{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# mT5 Model\n",
    "\n",
    "This section contains experiments and implementations using the **mT5** model.\n"
   ],
   "metadata": {
    "id": "vQuIwUUEIDIz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip -q install pandas pyarrow\n"
   ],
   "metadata": {
    "id": "ixG5uTqGw4zb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"opus_books\", \"en-es\", split=\"train\")\n",
    "\n",
    "print(ds)\n",
    "print(ds[0])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "e0d44b5661ba4485bdc5ae653f25a04b",
      "c7fe0de0137c4662a66b00e355fc5f67",
      "bd696dcd39d645c6a6098a358d58f8a7",
      "b9b3d4b82c284c7d99acafadef5f94b8",
      "68c474f2ee604f5cac2ba4252e759635",
      "c1649308916f494eb40add389ec9f86a",
      "eaca6e0da55b473783302f262351463a",
      "a4e7c1c82a644513b9aae5cf596e1fae",
      "83f5cf52d42e4073bf403eb0704f9103",
      "9e28178cd39448f6aa72d4e00c6ad8f3",
      "d8282633686d4d80a0048e6efc340ceb",
      "60caf00498f94d4192587bd4aaaf2820",
      "3ab7cb2ee3a440c7bb2e5a25c50f5d57",
      "6f383f0d41bf402da6e0831da35a6762",
      "65c6ffee24084ec0adae1d84b00857e0",
      "b1e0d10a470040809aca4f2cc2c6b9bd",
      "162e3d73894945ca89dfcf0478051374",
      "f1a3435b1ba94a53b27892ae04ac4a17",
      "393918a5edde49919d89a24553619a35",
      "09da8e3436344eff96b67064435526f9",
      "9a9bbf0784af46dfa40aad3396117921",
      "ce9b478cd10648858a14344e9ae24931"
     ]
    },
    "id": "65haD3pVzZMT",
    "outputId": "6318a7ac-eeca-42a5-f4fc-a01fe77b8bfa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "en-es/train-00000-of-00001.parquet:   0%|          | 0.00/16.1M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0d44b5661ba4485bdc5ae653f25a04b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/93470 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60caf00498f94d4192587bd4aaaf2820"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'translation'],\n",
      "    num_rows: 93470\n",
      "})\n",
      "{'id': '0', 'translation': {'en': 'Source: Project GutenbergAudiobook available here', 'es': 'Source: Wikisource & librodot.com'}}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "156be9bff0ea4d2aa05e6f5968b5d73a",
      "dd3187b187e44e6893ea263f53f3fbf7",
      "402261d3e6fc4000aab712a48020ef0b",
      "1fcc3e4e84f445318d660f50653f862a",
      "cc8c609ec6254bfcb5c0b4a6d5a3e294",
      "f898f58678fb47b9a706ba1806a3d33a",
      "d51f367b34044093b3e637c805f61a10",
      "cb269ffb0c3c48eca5178fbdefe30ad5",
      "7dd775517f7b4b69bcb1072df8fea880",
      "f0373875a0ab4667967c2d906971d1f7",
      "ffe7a0991e64411f8094ddb561b77b1d",
      "8493cc21e8024c28a0336267a8082efd",
      "8aba425b4db344798e837ae64d5ba37d",
      "1068773cf0034cb289bade732a2f0675",
      "1a2d7da74bd04e9cbe3f5b88a0b52bfe",
      "2546faf8a1e14c6d955667e1f31e3e84",
      "02a338e5b80c42829ced310bb1539027",
      "3ea27f42ad03408d897e7cdbbcbe6a66",
      "1a7959d2108044709be3ac721a5339fa",
      "b2c8ec1188e64b5b9adec12e9af7fc02",
      "b9908974a2b44f15994d2c16faab2f80",
      "2030ff6e25ba4c00a67a6ae74d5f8ecf",
      "d0f18732df6e45dea4c07619a1029701",
      "f39277c299c946f0a8b904d4ea331c9b",
      "c916127a0da1498a9383e77a9f4d6974",
      "94483a296ec0423a8899e5be7eaad786",
      "99117547b0ff48faa5a9ec21f23ea8a6",
      "13983bd36e5743b5be8f7273a001a38e",
      "31455a40bf4f4534989b335177f697fa",
      "1c519be6dcb84bfb9e601893d825503f",
      "d456da559d254775a58695e4f3691685",
      "805c7fd96f20420cae38129c2eff468e",
      "dde3620cc691443692eeca25ae642c19",
      "a345279c7b4b4e20a6b87b6c92e32f55",
      "6960a80b17074a82b3d1f8c0b745ec01",
      "b1053916e2964bf280dc33443fe0d6db",
      "978e4e4b295a4bcfa9dbbcd3a0656f8e",
      "4acfc3c903914e86947f2963dcc92347",
      "4efa49f4f3a5422a8be066ea33ae4aa7",
      "7ae68475619d4032a974bea39bafde33",
      "18cf66fff48c42fa8fe2de91f9953309",
      "3d9313ebb7cc4990a5a615996bd6b6be",
      "bdc8823a2a164b928f2dfb08d3b2344e",
      "7b2cacbbd1dd4360aad87b224f6e14d8"
     ]
    },
    "id": "UuZ1J3G7z1JP",
    "outputId": "2cf07c1f-16a2-486a-9f87-381a1e606920"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "156be9bff0ea4d2aa05e6f5968b5d73a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8493cc21e8024c28a0336267a8082efd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0f18732df6e45dea4c07619a1029701"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a345279c7b4b4e20a6b87b6c92e32f55"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess(batch):\n",
    "    # Spanish -> input\n",
    "    inputs = [ex[\"es\"] for ex in batch[\"translation\"]]\n",
    "    # English -> target\n",
    "    targets = [ex[\"en\"] for ex in batch[\"translation\"]]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=max_target_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ],
   "metadata": {
    "id": "Ab1wPp05z_iX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "small_ds = ds.select(range(2000))\n",
    "\n",
    "tokenized_ds = small_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=small_ds.column_names\n",
    ")\n",
    "\n",
    "print(tokenized_ds)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "94ff84dc168647689c2d780b704927a1",
      "0b31c24f5c1d489dae7d39d0cf72eb52",
      "297eed539d3249f7beb7e56953e976de",
      "c39e23b58f1c4c41a4a271c16e9f5371",
      "1cd0cda3424b45a19fe23c25a1d52086",
      "9f7f8fccc6fc4af7b8ae53c1e892b01d",
      "d323e59d61774df59c9abf2b48321ad1",
      "6cd68b149384436b9279a1736b67fb78",
      "c72d1dd167384d1496489549cd765488",
      "3e74526828f44432b3dd463cabc012ed",
      "4cb702ce85e9419bb4ee698e0a341111"
     ]
    },
    "id": "3v_0gh1P0EQh",
    "outputId": "53195985-1304-422e-9373-473a1f961e91"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94ff84dc168647689c2d780b704927a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_ds[0]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEP8kIIM0ICG",
    "outputId": "f67cf863-5add-4427-d901-694bb5617de3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [18510,\n",
       "  267,\n",
       "  20100,\n",
       "  15785,\n",
       "  549,\n",
       "  11393,\n",
       "  20038,\n",
       "  260,\n",
       "  284,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [18510,\n",
       "  267,\n",
       "  11265,\n",
       "  489,\n",
       "  229764,\n",
       "  58325,\n",
       "  4517,\n",
       "  4635,\n",
       "  2847,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "8e289073714a44c58ff0c9c1ba9f8a8e",
      "7b213cde40e34d7d91344a955cd78474",
      "df491cb8fff74109a5a5130ee0b39d7e",
      "4ac10af1473e4502839dde423f970323",
      "7209df4f4e1142fa901174ee2948d2d5",
      "58d569592f3f409b9008c8f406f11fbd",
      "ede0f0f271154eab80b72375075060d3",
      "45f1f4f102a8428e8bbac14c7a2c2b95",
      "ed7f792a0bf54858b05f186a874e9f3a",
      "637a47382ff04a378f30a615e70d3242",
      "e8b149467e884e8ba1e852e949e19188",
      "fec3ac267c844c429e40a071aeac1f50",
      "4b1f16bca1ba456ab009ab7d48597bc0",
      "9d76057c3e644f15aa3f5264bc38ab0f",
      "70c6f04a9fae41c5ae1d094d8471f3ef",
      "16c732f1f1ee491fa295c704767560e9",
      "de367b91f429453e96570b4cb6b4cd22",
      "20e466e3e6184b7caf68cd19aa3c304c",
      "e5a9c06a6d234d2abc7d059cbdcb43d0",
      "7f03227aad93455f85f83bc4af0266cd",
      "ce25edfd6fc84e67b7e397472d62f7d6",
      "025c721bb254424b858e6ddefbbe0476",
      "8cb33eb3f41a4a90bd4016f5458c340f",
      "70b0e3624d424cf28c90bcd3d7638557",
      "cb02f21a681749d0aa086f2771994dfc",
      "986a3f7614c14105b6481f0037866968",
      "b257ae8ef1f345139330b88097640bf6",
      "c4f0a3bf13fb4d6881a858d2e0e12eca",
      "8702362484a04c5da06df223a67ec6bb",
      "62546b8cd5074b2ca84e1052d9d5868e",
      "f74258b1d9b149d581945d5eaf104447",
      "ec9a3629cc114ff488916822e6239e9d",
      "a41197b3443c450696d4ba85cc61961c"
     ]
    },
    "id": "yc8zK4BX0Uq3",
    "outputId": "ad95b058-d03c-4404-8713-220efb71a85a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e289073714a44c58ff0c9c1ba9f8a8e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fec3ac267c844c429e40a071aeac1f50"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cb33eb3f41a4a90bd4016f5458c340f"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")\n"
   ],
   "metadata": {
    "id": "KFSQ-H1T0cqf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mt5-es-en\",\n",
    "    eval_strategy=\"no\",          # <-- DEÄžÄ°ÅžTÄ°\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ],
   "metadata": {
    "id": "NvSKWY4F0qFB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8ptp1mK0raO",
    "outputId": "74cda552-ad31-4dd6-ebe2-e88bbbb89acc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-843492235.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "e0w680oJ062w",
    "outputId": "61e9ede8-123a-4a0e-8428-e1b48c472283"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 02:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.0, metrics={'train_runtime': 125.2234, 'train_samples_per_second': 15.971, 'train_steps_per_second': 0.998, 'total_flos': 264374845440000.0, 'train_loss': 0.0, 'epoch': 1.0})"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess(batch):\n",
    "    # PREFIX EKLENÄ°YOR ðŸ”¥\n",
    "    inputs = [\n",
    "        \"translate Spanish to English: \" + ex[\"es\"]\n",
    "        for ex in batch[\"translation\"]\n",
    "    ]\n",
    "    targets = [ex[\"en\"] for ex in batch[\"translation\"]]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=max_target_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ],
   "metadata": {
    "id": "lX2wHq6N2F6s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "small_ds = ds.select(range(2000))\n",
    "\n",
    "tokenized_ds = small_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=small_ds.column_names\n",
    ")\n",
    "\n",
    "tokenized_ds[0]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7185abf8604c4a12b35fa099f374cdbd",
      "db5b743bf6e1435da9116a654a58ef54",
      "62390d0c5eda4035b78f45623e44a4b4",
      "03aef48e2bac49d3bd3bfba258449d65",
      "89153184122349eea78b8daea5740bad",
      "887ceaeb4618481995930e5dff598351",
      "877fe0da319b4479a79743405ba04a27",
      "79881abe8b324f56ab7916ccdf4dd60a",
      "61aa95dd9ca24d0f8896ebbcf66120da",
      "b0c9e9f032614556bd3d40c2d375cc07",
      "2052e457ac3c42fc95b97fe8530f08ce"
     ]
    },
    "id": "PaPfPUcg2HU8",
    "outputId": "860f8089-b710-4d80-ac76-2e99873ca770"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7185abf8604c4a12b35fa099f374cdbd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4169: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [37194,\n",
       "  259,\n",
       "  29037,\n",
       "  288,\n",
       "  5413,\n",
       "  267,\n",
       "  18510,\n",
       "  267,\n",
       "  20100,\n",
       "  15785,\n",
       "  549,\n",
       "  11393,\n",
       "  20038,\n",
       "  260,\n",
       "  284,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [18510,\n",
       "  267,\n",
       "  11265,\n",
       "  489,\n",
       "  229764,\n",
       "  58325,\n",
       "  4517,\n",
       "  4635,\n",
       "  2847,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n"
   ],
   "metadata": {
    "id": "9kR9d-LJ2LOM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "V47HluBM2Pzx",
    "outputId": "5d6ef4d5-ae45-4979-ba6e-035d85b7e949"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-39801834.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.0, metrics={'train_runtime': 190.3438, 'train_samples_per_second': 10.507, 'train_steps_per_second': 0.657, 'total_flos': 264374845440000.0, 'train_loss': 0.0, 'epoch': 1.0})"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def translate_es_to_en(text):\n",
    "    prefixed_text = \"translate Spanish to English: \" + text\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prefixed_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=128,\n",
    "        num_beams=4\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ],
   "metadata": {
    "id": "keGdbJXU3BEz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(translate_es_to_en(\"Este proyecto es muy interesante y educativo.\"))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGHijA6N3D2s",
    "outputId": "5fdcea39-e66a-4c16-9847-176c999e73be"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<0x03>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess(batch):\n",
    "    # Spanish -> input (prefix ile)\n",
    "    inputs = [\"translate Spanish to English: \" + ex[\"es\"] for ex in batch[\"translation\"]]\n",
    "    targets = [ex[\"en\"] for ex in batch[\"translation\"]]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True\n",
    "        # padding YOK! (dinamik padding'i data collator yapacak)\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=max_target_length,\n",
    "        truncation=True\n",
    "        # padding YOK!\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    # pad tokenlarÄ±nÄ± loss'tan Ã§Ä±kar: pad_token_id -> -100\n",
    "    pad = tokenizer.pad_token_id\n",
    "    labels = [[(tok if tok != pad else -100) for tok in seq] for seq in labels]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7C164FWf3UFl",
    "outputId": "4bf40757-a88f-4367-ded7-3253d044faa7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "small_ds = ds.select(range(4000))  # 2000 de olur, biraz artÄ±rdÄ±m\n",
    "\n",
    "tokenized_ds = small_ds.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=small_ds.column_names\n",
    ")\n",
    "\n",
    "print(tokenized_ds[0].keys())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "6b8c10d701af4c2697c3708e00659581",
      "02c79d70961246158d5e251c7788cf2d",
      "3da718eaf1864464b555972a06d60449",
      "036e601b160b4214921bbbaa7e80874e",
      "324fa4aece0547adb08793367b2e246a",
      "28751a3534664ebd96142d4c15108bdd",
      "eb07d84b81134275a5e7e565ac3e6c4b",
      "60bae8de10c74a20a3b23ea2ae2cf11f",
      "8851e6b50fa544929c5c54b8dca27363",
      "7b752486165845b5865f1836992d1097",
      "de58be5d95d0474290f76912ad6195d8"
     ]
    },
    "id": "DbHZsTlN3XFi",
    "outputId": "6ea54793-a396-4b5f-b242-69cc10a83a9b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b8c10d701af4c2697c3708e00659581"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Trainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "bWM6DpO73aAl",
    "outputId": "5c2278b0-3a85-44fc-c17b-3f6f9fbcfe4e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-524115615.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 04:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.0, metrics={'train_runtime': 280.3474, 'train_samples_per_second': 14.268, 'train_steps_per_second': 0.892, 'total_flos': 352704959815680.0, 'train_loss': 0.0, 'epoch': 1.0})"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def translate_es_to_en(text):\n",
    "    prefixed = \"translate Spanish to English: \" + text\n",
    "    inputs = tokenizer(prefixed, return_tensors=\"pt\", truncation=True, max_length=128).to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=64, num_beams=4)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(translate_es_to_en(\"Este proyecto es muy interesante y educativo.\"))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCwW8jkd5bfe",
    "outputId": "2b41906e-1298-47f3-d976-be4444274118"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<0x03>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(ds[200][\"translation\"][\"es\"])\n",
    "print(ds[200][\"translation\"][\"en\"])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_83CApR5hEr",
    "outputId": "55063661-120e-49a5-9200-ae8f5f53a343"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Es evidente, a pesar de su asidua atenciÃ³n cuando ella dibuja, que de hecho no sabe nada en esta materia.\n",
      "It is evident, in spite of his frequent attention to her while she draws, that in fact he knows nothing of the matter.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_es = ds[200][\"translation\"][\"es\"]\n",
    "print(\"Spanish:\", test_es)\n",
    "print(\"English (model):\", translate_es_to_en(test_es))\n",
    "print(\"English (gold):\", ds[200][\"translation\"][\"en\"])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oU3xyqDr5uUq",
    "outputId": "8680a96e-895e-4528-edff-b9b8b580ae45"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spanish: Es evidente, a pesar de su asidua atenciÃ³n cuando ella dibuja, que de hecho no sabe nada en esta materia.\n",
      "English (model): <0x03>\n",
      "English (gold): It is evident, in spite of his frequent attention to her while she draws, that in fact he knows nothing of the matter.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.config.decoder_start_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n"
   ],
   "metadata": {
    "id": "Ac-VTs_X54-G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def translate_es_to_en(text):\n",
    "    prefixed = \"translate Spanish to English: \" + text\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prefixed,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ],
   "metadata": {
    "id": "mkxBJE4K56Yt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Spanish:\", ds[200][\"translation\"][\"es\"])\n",
    "print(\"English (model):\", translate_es_to_en(ds[200][\"translation\"][\"es\"]))\n",
    "print(\"English (gold):\", ds[200][\"translation\"][\"en\"])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnWntlM458xJ",
    "outputId": "2c4b1a7c-aa1e-4b79-b5d3-8af470a3c8c9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spanish: Es evidente, a pesar de su asidua atenciÃ³n cuando ella dibuja, que de hecho no sabe nada en esta materia.\n",
      "English (model): <0x03>\n",
      "English (gold): It is evident, in spite of his frequent attention to her while she draws, that in fact he knows nothing of the matter.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(translate_es_to_en(\"Este proyecto es muy interesante y educativo.\"))\n"
   ],
   "metadata": {
    "id": "OGNMiBJQ6BwC",
    "outputId": "1dffa143-0496-4014-f463-0dd081db3eb5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<0x03>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FLAN-T5 Model\n",
    "\n",
    "This section contains experiments and implementations using the **FLAN-T5** model."
   ],
   "metadata": {
    "id": "dzaG8bbeBl3-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-base\"  # RAM zorlanÄ±rsa flan-t5-small\n",
    "flan_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "flan_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "def flan_translate_es_en(text):\n",
    "    prompt = f\"Translate Spanish to English: {text}\"\n",
    "    inputs = flan_tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    ).to(flan_model.device)\n",
    "\n",
    "    outputs = flan_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=80,\n",
    "        num_beams=4\n",
    "    )\n",
    "    return flan_tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "e67f4a0eebf0440fba1214bc84f049dd",
      "29de0776e7aa4f84a2b93343915e40a6",
      "0eddc4e5de95466cbeef3f22ddb77173",
      "d2b6afe42b46406385b1bd0e71c7a022",
      "b88f9023a228477abd2c6965fd2b8b1f",
      "3ae9b48cbfb44fb2aeb8a7247ad11be2",
      "fbec7013f56e4ff8929e734ead608090",
      "7d3714ace7a34da6a4a80e29d57178e9",
      "514da7b0c2b8468d92d08b4b79593d67",
      "050879cb4670459f802d5d3d99f2259a",
      "04e39f524d4544008f6906a57c165a2a",
      "55c66ec4af114e7ea1889cb14d361480",
      "4c3bd85ec680414ab0ca01ed7111324b",
      "85c668a6dacf4b198d007130488c26e0",
      "064ffbee16ba4bc8966d42c65989ff9d",
      "7d35a22b03b24109b3238fd473412a83",
      "419345af2a164b9fa1d128f430226726",
      "88856b81401242b2b4453294ab1e42d0",
      "b1fc467587ef4c7ea3509cd8f83340b9",
      "aaba615b4eb94ec4b0a0cd2c3d9185f0",
      "a8fe5ffac8144b7e97afce65c1e91d40",
      "c89f1d8adaaa45a3a055399bfb7aa624",
      "b564a94ab18d4de093e7312be481b9ed",
      "b56678f405984b358246bb9a1153728e",
      "cf2254490ee5428b97d4688deeb1852d",
      "c0464cc650df4e9cb843077db3a20e1e",
      "918c8470365447ef9aab9ee26d62038f",
      "11f271fffa444912b32dfba2b3939c5e",
      "baf0eb03119e4df980456af2710638ef",
      "bfd93cefcbd64e36837ed9cb93c8aedb",
      "df7a4379771c4e02a1ae22ca8dea1d9d",
      "92a1b22e55674768a1ba2ce863c06947",
      "07973670615d400a90ffdb76deb1169e",
      "5375b48daf3c4fbbb3e5df24504526df",
      "1d9b8ba119d044eca00b2c51874a33d0",
      "b7f42910c40c4e5689ac706efe9319d3",
      "226d023f1c3449ee85d32f25d8808977",
      "f1cd4dec3d924bd3b05dc3e353f8f99f",
      "45d3ccb23dfc404a83804caf72c28414",
      "c42d6216cc6f46be87bfd56ff344a605",
      "21e3474d64fd487abc66495646f448c3",
      "c22a5e7724d0458f9285505cc476dd2b",
      "23455ad1e0f74592a4b9bc1a9f9d71b8",
      "3e56dba407394257b6c9281a64d7b4b2",
      "16543e1fcf3a476a90d5eed70e37ff7b",
      "ffcf924e3eb34b4791dea3343d12de17",
      "d8826b845d394462a57dfb536cf70de2",
      "62c15518402943c4b1dade37633be289",
      "9ba2780987114330b046603d6d7d4484",
      "7d7d8c3e2ca3468ba908365a02afe40a",
      "1563c3d862b3410eb295f075b23d8638",
      "5f0dfd13d7394ac48f460dc692f5327f",
      "241718d90ff24de59808f902411e9bcb",
      "9df77037f4af4b6d8588bb2fe9179449",
      "258868a082e44071afd2a77c1a5029d4",
      "c8fe38a2bdcf4e7988d03ae4e39fcf4d",
      "b77fde51f15e4704b91c3d1469efecde",
      "ae2fa923bec44d1fae8fe1bb70dc73a7",
      "4704a2545985458da16cb3368788aae3",
      "bd056b17d9c74df69d434b5fdc6ea1ee",
      "0653ddb3a8234eb4a69726211372a316",
      "4d0ade58cdf14421b18e825eb91b3aff",
      "aaf9b3d6b58d41b7a687b84a95a763a4",
      "2e689b182fcc4b83928061111c7ca934",
      "10f213c44b6848de9970936aa5386529",
      "23243914a7dd40948cc91dd661d15a1c",
      "4f285412263b4cd9bd8837a26a217850",
      "cdb4df7112704b75a93147c3addbd718",
      "846c40adf8df455fb3c16da53bf61f95",
      "f0fed5db19ff4246b1059bf72f653ba8",
      "3df3e53477ad487a9c3daa0817859d8c",
      "d41bf297320446eb997124f7aa3fc816",
      "47750875db4e41059d118a69b5e70a41",
      "477145e26a2947e9a9fc74a0d196a844",
      "c2e8c5bffefb4c3ca2d2cb237430d459",
      "0b657c6358eb455cbc76d74f915afb1a",
      "7bf87ca20ea34e4ba855ed63cfd37220"
     ]
    },
    "id": "dvMinM-lBo5V",
    "outputId": "dcb0c19a-d4be-447c-ce00-6aaa43e3cfc9"
   },
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e67f4a0eebf0440fba1214bc84f049dd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55c66ec4af114e7ea1889cb14d361480"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b564a94ab18d4de093e7312be481b9ed"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5375b48daf3c4fbbb3e5df24504526df"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16543e1fcf3a476a90d5eed70e37ff7b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8fe38a2bdcf4e7988d03ae4e39fcf4d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f285412263b4cd9bd8837a26a217850"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"FLAN:\", flan_translate_es_en(\"Este proyecto es muy interesante y educativo.\"))\n",
    "print(\"FLAN (dataset):\", flan_translate_es_en(ds[200][\"translation\"][\"es\"]))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSRl8VVlBt_m",
    "outputId": "db30e8a1-af52-4ce0-a881-c20a1762bb0d"
   },
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FLAN: This project is very interesting and educational.\n",
      "FLAN (dataset): It is obvious, despite her attention to detail when she sketches, that she in fact does not know anything about this subject.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "splits = ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = splits[\"train\"]\n",
    "test_ds  = splits[\"test\"]\n",
    "\n",
    "print(train_ds, test_ds)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UX91i-g0CcIE",
    "outputId": "92fb29b3-e6e0-49e6-edfc-4de31f483cf7"
   },
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'translation'],\n",
      "    num_rows: 84123\n",
      "}) Dataset({\n",
      "    features: ['id', 'translation'],\n",
      "    num_rows: 9347\n",
      "})\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "N = 200\n",
    "test_sample = test_ds.select(range(N))\n",
    "\n",
    "print(\"Test sample size:\", len(test_sample))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGWmFofRCd9g",
    "outputId": "b46bba57-edfe-48da-cb05-2269ec58c60c"
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test sample size: 200\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip -q install evaluate sacrebleu\n",
    "\n",
    "import evaluate\n",
    "bleu = evaluate.load(\"sacrebleu\")\n"
   ],
   "metadata": {
    "id": "UMrBIkzPCx-R"
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "preds = []\n",
    "refs = []\n",
    "\n",
    "for ex in test_sample:\n",
    "    src = ex[\"translation\"][\"es\"]\n",
    "    ref = ex[\"translation\"][\"en\"]\n",
    "\n",
    "    pred = flan_translate_es_en(src)\n",
    "    preds.append(pred)\n",
    "    refs.append([ref])   # sacrebleu formatÄ±\n",
    "\n",
    "result = bleu.compute(predictions=preds, references=refs)\n",
    "print(\"FLAN-T5 BLEU:\", result[\"score\"])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIDXef-sC11x",
    "outputId": "39390039-7407-4b99-9f95-6c86087bdacc"
   },
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FLAN-T5 BLEU: 9.584217024662964\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "result_chrf = chrf.compute(predictions=preds, references=refs)\n",
    "print(\"FLAN-T5 chrF:\", result_chrf[\"score\"])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "1dfaabeda25541f08a3eeff2a606b063",
      "7646b903e7b340a1b89551a333489321",
      "da4ed0aa02ba40a8a4a5668ecba7e077",
      "3c5a9e4bf95c4214a33162b4ec34dbd6",
      "b011f1d3a38b4a6398bf5557ab755a32",
      "986d98d4c5474701ab0680a97b8cfc2e",
      "3926c242b06c414d8ff69e5454498b75",
      "e06e1a0d82a8469a98cf89a16d1e0d22",
      "cd697f4528814a2b9ea3fbc3dd84af61",
      "cb79dc8151f64bf187dcea43cbce8ddf",
      "5515e9faa2494cb794b4bd789d9d0b10"
     ]
    },
    "id": "0z6cD8xzFn_2",
    "outputId": "ebdd9976-f54b-417d-aece-a1b7beef3960"
   },
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dfaabeda25541f08a3eeff2a606b063"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FLAN-T5 chrF: 34.019770630584205\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for i in range(5):\n",
    "    ex = test_sample[i]\n",
    "    src = ex[\"translation\"][\"es\"]\n",
    "    ref = ex[\"translation\"][\"en\"]\n",
    "    flan_out = flan_translate_es_en(src)\n",
    "\n",
    "    rows.append({\n",
    "        \"Spanish\": src,\n",
    "        \"FLAN-T5 Output\": flan_out,\n",
    "        \"Reference (EN)\": ref,\n",
    "        \"Meaning Preserved?\": \"Yes\" if flan_out else \"â€”\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "RtA1fqrLFrF4",
    "outputId": "65dd840a-7b27-47b1-e3bb-e405656bf4c5"
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             Spanish  \\\n",
       "0  Kitty, al contrario, estaba mÃ¡s activa a inclu...   \n",
       "1   Se darÃ¡n las Ã³rdenes necesarias para su regreso.   \n",
       "2   Â¡Demasiado larga ha sido ya la pausa! Â¡Adelante!   \n",
       "3                               Jueves 20 de agosto.   \n",
       "4                                         RichelieuÂ»   \n",
       "\n",
       "                                      FLAN-T5 Output  \\\n",
       "0  Kitty, on the other hand, was more active and ...   \n",
       "1  You will be given the orders needed for your r...   \n",
       "2               Very long has already been the pain!   \n",
       "3                                Thursday 20 August.   \n",
       "4                                         RichelieuÂ»   \n",
       "\n",
       "                                      Reference (EN) Meaning Preserved?  \n",
       "0  Kitty, on the contrary, was more active than u...                Yes  \n",
       "1  All necessary preparations shall be made for y...                Yes  \n",
       "2      Maintenant partons, allons, allons vers Sion.                Yes  \n",
       "3                                     Thursday, Aug.                Yes  \n",
       "4                                        \"Richelieu\"                Yes  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-e5e21a73-16b5-4ae6-ae0a-73e7b17c59e4\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spanish</th>\n",
       "      <th>FLAN-T5 Output</th>\n",
       "      <th>Reference (EN)</th>\n",
       "      <th>Meaning Preserved?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kitty, al contrario, estaba mÃ¡s activa a inclu...</td>\n",
       "      <td>Kitty, on the other hand, was more active and ...</td>\n",
       "      <td>Kitty, on the contrary, was more active than u...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Se darÃ¡n las Ã³rdenes necesarias para su regreso.</td>\n",
       "      <td>You will be given the orders needed for your r...</td>\n",
       "      <td>All necessary preparations shall be made for y...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Â¡Demasiado larga ha sido ya la pausa! Â¡Adelante!</td>\n",
       "      <td>Very long has already been the pain!</td>\n",
       "      <td>Maintenant partons, allons, allons vers Sion.</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jueves 20 de agosto.</td>\n",
       "      <td>Thursday 20 August.</td>\n",
       "      <td>Thursday, Aug.</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RichelieuÂ»</td>\n",
       "      <td>RichelieuÂ»</td>\n",
       "      <td>\"Richelieu\"</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5e21a73-16b5-4ae6-ae0a-73e7b17c59e4')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e5e21a73-16b5-4ae6-ae0a-73e7b17c59e4 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e5e21a73-16b5-4ae6-ae0a-73e7b17c59e4');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-886001c0-3290-4b4b-bfe0-afbad8340f98\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-886001c0-3290-4b4b-bfe0-afbad8340f98')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-886001c0-3290-4b4b-bfe0-afbad8340f98 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_9c1b06c3-abcc-4fb3-a9f4-51c4dd8252d6\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_9c1b06c3-abcc-4fb3-a9f4-51c4dd8252d6 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df",
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Spanish\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Se dar\\u00e1n las \\u00f3rdenes necesarias para su regreso.\",\n          \"Richelieu\\u00bb\",\n          \"\\u00a1Demasiado larga ha sido ya la pausa! \\u00a1Adelante!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAN-T5 Output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"You will be given the orders needed for your return.\",\n          \"Richelieu\\u00bb\",\n          \"Very long has already been the pain!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reference (EN)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"All necessary preparations shall be made for your return.\",\n          \"\\\"Richelieu\\\"\",\n          \"Maintenant partons, allons, allons vers Sion.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Meaning Preserved?\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 55
    }
   ]
  }
 ]
}